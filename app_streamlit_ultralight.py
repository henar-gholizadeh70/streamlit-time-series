
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

st.set_page_config(page_title="Streamlit Light App", layout="wide")
st.title("ğŸ“Š Ù†Ø³Ø®Ù‡ Ø³Ø¨Ú© Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† Streamlit")

st.write("âœ… Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø¨Ø¯ÙˆÙ† Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ú¯ÛŒÙ† Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª.")

# --- Cleaned code from notebook (no sklearn, tensorflow, etc.) ---
import pandas as pd

df = pd.read_csv("dataset_to_nonhyper.csv")
df

if 'Unnamed: 0' in df.columns:
    df.drop('Unnamed: 0', axis=1, inplace=True)

df['date'] = pd.to_datetime(df['date'])

# Sort by participant and date
df = df.sort_values(by=['participant_id', 'date'])
df

# check for resonal variable
print(df[['blood_pressure_systolic', 'blood_pressure_diastolic']].describe())

original_shape = df.shape

#check for missing value
df = df.dropna(subset=['time_to_event', 'blood_pressure_systolic', 'blood_pressure_diastolic'])

print("Original shape:", original_shape)
print("New shape after dropna:", df.shape)

print("Unique participants:", df['participant_id'].nunique())

# 1. Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ ÙØ´Ø§Ø± Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ© Ùˆ Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ©
sd_df = df.groupby('date')[['blood_pressure_systolic', 'blood_pressure_diastolic']].mean()

# 2. Ù‡Ù…ÙˆØ§Ø±Ø³Ø§Ø²ÛŒ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú© Û· Ø±ÙˆØ²Ù‡
sd_df_smooth = sd_df.rolling(window=7).mean()

# 3. Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ØµÙ„ÛŒ Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ù‡Ù…ÙˆØ§Ø±Ø´Ø¯Ù‡ Ø¯Ø± Ú©Ù†Ø§Ø± Ù‡Ù…
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(18, 5))

sd_df.plot(ax=axes[0], title='Original Blood Pressure (Daily Average)')
sd_df_smooth.plot(ax=axes[1], title='Smoothed Blood Pressure (7-day MA)')

plt.tight_layout()
plt.show()

grouped = df.groupby('participant_id')
participant_series = {
    pid: group.set_index('date')['time_to_event'].sort_index()
    for pid, group in grouped
    if len(group) >= 12
}

print("Participants with â‰¥ 10 visits:", len(participant_series))

sample_pid = list(participant_series.keys())[0]
sample_series = participant_series[sample_pid]
print(f"\nSample time series for participant {sample_pid}:\n")
print(sample_series.head())

import matplotlib.pyplot as plt

sample_ids = list(participant_series.keys())[:3]

plt.figure(figsize=(16, 6))  # ÙØ¶Ø§ÛŒ Ø§ÙÙ‚ÛŒ Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§

for pid in sample_ids:
    series = participant_series[pid]
    plt.plot(series.index, series.values, marker='o', label=f'Participant {pid}')

plt.title("Time to Event Countdown for Sample Participants")
plt.xlabel("Date")
plt.ylabel("Time to Event")

plt.legend()
plt.grid(True)
plt.xticks(rotation=45)


# Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ØªØ§Ø±ÛŒØ® Ø±ÙˆÛŒØ¯Ø§Ø¯ Ù‡Ø± ÙØ±Ø¯
event_dates = {}

for pid, series in participant_series.items():
    zero_event = series[series == 0]
    if not zero_event.empty:
        event_dates[pid] = zero_event.index[0]  # Ø§ÙˆÙ„ÛŒÙ† ØªØ§Ø±ÛŒØ® Ú©Ù‡ time_to_event = 0 Ø´Ø¯Ù‡

bp_by_person = {}

for pid, event_date in event_dates.items():
    sub_df = df[df['participant_id'] == pid].copy()
    sub_df['date'] = pd.to_datetime(sub_df['date'])
    sub_df = sub_df.sort_values('date')

    # Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø§Ø² 14 Ø±ÙˆØ² Ù‚Ø¨Ù„ ØªØ§ Ø±ÙˆØ² event
    bp_window = sub_df[(sub_df['date'] <= event_date) &
                       (sub_df['date'] >= event_date - pd.Timedelta(days=14))]

    bp_by_person[pid] = bp_window[['date', 'blood_pressure_systolic', 'blood_pressure_diastolic']]

import matplotlib.pyplot as plt

for pid, bp_data in list(bp_by_person.items())[:3]:  # ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ 3 Ù†ÙØ± Ø§ÙˆÙ„
    plt.figure(figsize=(10, 4))
    plt.plot(bp_data['date'], bp_data['blood_pressure_systolic'], label='Systolic', marker='o')
    plt.plot(bp_data['date'], bp_data['blood_pressure_diastolic'], label='Diastolic', marker='x')

    plt.axvline(event_dates[pid], color='red', linestyle='--', label='Event (TTE = 0)')
    plt.title(f'Blood Pressure Before Event - Participant {pid}')
    plt.xlabel('Date')
    plt.ylabel('Blood Pressure')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# for example choose the first one and give its data from the main dataset and provide the date as a index for time series analysis.
sample_pid = sample_ids[0]
participant_data = df[df['participant_id'] == sample_pid].copy()
participant_data = participant_data.sort_values(by='date')
participant_data.set_index('date', inplace=True)

# Rolling averages
# 7-day rolling averages for deeper trend smoothing
participant_data['rolling_mean_7_systolic'] = participant_data['blood_pressure_systolic'].rolling(window=7).mean()
participant_data['rolling_mean_7_diastolic'] = participant_data['blood_pressure_diastolic'].rolling(window=7).mean()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

# Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ØµÙ„ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©
plt.plot(participant_data.index, participant_data['blood_pressure_systolic'], label='Original Systolic', alpha=0.4)

# Ù†Ù…ÙˆØ¯Ø§Ø± Ù‡Ù…ÙˆØ§Ø±Ø´Ø¯Ù‡ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Û· Ø±ÙˆØ²Ù‡
plt.plot(participant_data.index, participant_data['rolling_mean_7_systolic'], label='Smoothed (7-day MA)', linewidth=2)

plt.title('Systolic Blood Pressure: Original vs Smoothed')
plt.xlabel('Date')
plt.ylabel('Systolic BP (mmHg)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(12, 5))

# Ù†Ù…ÙˆØ¯Ø§Ø± Ø§ØµÙ„ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ©
plt.plot(participant_data.index, participant_data['blood_pressure_diastolic'], label='Original Diastolic', alpha=0.4)

# Ù†Ù…ÙˆØ¯Ø§Ø± Ù‡Ù…ÙˆØ§Ø±Ø´Ø¯Ù‡ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Û· Ø±ÙˆØ²Ù‡
plt.plot(participant_data.index, participant_data['rolling_mean_7_diastolic'], label='Smoothed (7-day MA)', linewidth=2)

plt.title('Diastolic Blood Pressure: Original vs Smoothed')
plt.xlabel('Date')
plt.ylabel('Diastolic BP (mmHg)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

sample_pid = sample_ids[0]
participant_data = df[df['participant_id'] == sample_pid].copy()
participant_data = participant_data.sort_values(by='date')
participant_data.set_index('date', inplace=True)

# Rolling averages
# 7-day rolling averages for deeper trend smoothing
participant_data['rolling_mean_7_systolic'] = participant_data['blood_pressure_systolic'].rolling(window=7).mean()
participant_data['rolling_mean_7_diastolic'] = participant_data['blood_pressure_diastolic'].rolling(window=7).mean()

# Applying a 7-day moving average to align noise and indicate the real trends
# Use the columns with the rolling averages from participant_data
participant_data[['rolling_mean_7_systolic', 'rolling_mean_7_diastolic']].plot(figsize=(12, 5), title='7-Day Moving Average of Blood Pressure')
plt.ylabel('mmHg')
plt.grid(True)
plt.show()

# Use the columns with the rolling averages from participant_data which we used in for moving average
# Store the rolling average data in a variable
rolling = participant_data['rolling_mean_7_systolic']
# Now calculate residuals using participant_data and the rolling average
# Note: This calculates residuals for a single participant (sample_pid)
residuals = participant_data['blood_pressure_systolic'] - rolling
threshold = 1.5 * residuals.std()
anomalies = residuals[abs(residuals) > threshold]
plt.figure(figsize=(12, 5))
# Plot the original systolic BP for the participant
plt.plot(participant_data.index, participant_data['blood_pressure_systolic'], label='blood_pressure_systolic')
# Scatter plot anomalies
plt.scatter(anomalies.index, participant_data.loc[anomalies.index]['blood_pressure_systolic'], color='red', label='Anomalies')
plt.title(f'Anomalies in Systolic BP (based on moving average) - Participant {sample_pid}')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# ÙØ±Ø¶: participant_id Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±ÛŒ Ùˆ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø§ÙˆÙ„ÛŒ Ø±Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒ
sample_pid = df['participant_id'].unique()[0]

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¢Ù† Ø´Ø±Ú©Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡
participant_data = df[df['participant_id'] == sample_pid].sort_values('date')
participant_data = participant_data.set_index('date')

# Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…ÙˆØ±Ø¯ Ø¨Ø±Ø±Ø³ÛŒ: time_to_event
ts = participant_data['blood_pressure_systolic']

# Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ† Ø¯ÛŒÚ©ÛŒ ÙÙˆÙ„Ø±
adf_result = adfuller(ts.dropna())
print("ADF Statistic:", adf_result[0])
print("p-value:", adf_result[1])
for key, value in adf_result[4].items():
    print(f"Critical Value ({key}): {value}")

# ØªÙØ³ÛŒØ± Ù†ØªÛŒØ¬Ù‡
if adf_result[1] < 0.05:
    print("\nâœ… Series is stationary (reject H0)")
else:
    print("\nâŒ Series is non-stationary (fail to reject H0)")

import matplotlib.pyplot as plt

# Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ time_to_event
ts = participant_data['blood_pressure_systolic']

# Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± ACF
plt.figure(figsize=(10, 5))
plot_acf(ts.dropna(), lags=5)  # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§ 30 lag
plt.title(f"Autocorrelation (ACF) - blood_pressure_systolic for participant {sample_pid}")
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# ÙØ±Ø¶: participant_id Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±ÛŒ Ùˆ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø§ÙˆÙ„ÛŒ Ø±Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒ
sample_pid = df['participant_id'].unique()[0]

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¢Ù† Ø´Ø±Ú©Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡
participant_data = df[df['participant_id'] == sample_pid].sort_values('date')
participant_data = participant_data.set_index('date')

# Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…ÙˆØ±Ø¯ Ø¨Ø±Ø±Ø³ÛŒ: time_to_event
ts = participant_data['blood_pressure_diastolic']

# Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ† Ø¯ÛŒÚ©ÛŒ ÙÙˆÙ„Ø±
adf_result = adfuller(ts.dropna())
print("ADF Statistic:", adf_result[0])
print("p-value:", adf_result[1])
for key, value in adf_result[4].items():
    print(f"Critical Value ({key}): {value}")

# ØªÙØ³ÛŒØ± Ù†ØªÛŒØ¬Ù‡
if adf_result[1] < 0.05:
    print("\nâœ… Series is stationary (reject H0)")
else:
    print("\nâŒ Series is non-stationary (fail to reject H0)")

import matplotlib.pyplot as plt

# Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ time_to_event
ts = participant_data['blood_pressure_diastolic']

# Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± ACF
plt.figure(figsize=(10, 5))
plot_acf(ts.dropna(), lags=5)  # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§ 30 lag
plt.title(f"Autocorrelation (ACF) - blood_pressure_diastolic for participant {sample_pid}")
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# ÙØ±Ø¶: participant_id Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±ÛŒ Ùˆ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø§ÙˆÙ„ÛŒ Ø±Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒ
sample_pid = df['participant_id'].unique()[0]

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¢Ù† Ø´Ø±Ú©Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡
participant_data = df[df['participant_id'] == sample_pid].sort_values('date')
participant_data = participant_data.set_index('date')

# Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…ÙˆØ±Ø¯ Ø¨Ø±Ø±Ø³ÛŒ: time_to_event
ts = participant_data['time_to_event']

# Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ† Ø¯ÛŒÚ©ÛŒ ÙÙˆÙ„Ø±
adf_result = adfuller(ts.dropna())
print("ADF Statistic:", adf_result[0])
print("p-value:", adf_result[1])
for key, value in adf_result[4].items():
    print(f"Critical Value ({key}): {value}")

# ØªÙØ³ÛŒØ± Ù†ØªÛŒØ¬Ù‡
if adf_result[1] < 0.05:
    print("\nâœ… Series is stationary (reject H0)")
else:
    print("\nâŒ Series is non-stationary (fail to reject H0)")

import matplotlib.pyplot as plt

# Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ time_to_event
ts = participant_data['time_to_event']

# Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± ACF
plt.figure(figsize=(10, 5))
plot_acf(ts.dropna(), lags=5)  # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§ 30 lag
plt.title(f"Autocorrelation (ACF) - time_to_event for participant {sample_pid}")
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd

# ÙØ±Ø¶: df Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ['time_to_event', 'systolic', 'diastolic']

# Ø§ÛŒØ³ØªØ§Ø³Ø§Ø²ÛŒ time_to_event
df['diff_time_to_event'] = df['time_to_event'].diff()
df.dropna(inplace=True)

# ØªØ³Øª Ú¯Ø±Ù†Ø¬Ø± Ø¨ÛŒÙ† systolic â†’ time_to_event
print("Granger test: systolic â†’ time_to_event")
grangercausalitytests(df[['diff_time_to_event', 'blood_pressure_systolic']], maxlag=5)

# ØªØ³Øª Ú¯Ø±Ù†Ø¬Ø± Ø¨ÛŒÙ† diastolic â†’ time_to_event
print("Granger test: diastolic â†’ time_to_event")
grangercausalitytests(df[['diff_time_to_event', 'blood_pressure_diastolic']], maxlag=5)

import matplotlib.pyplot as plt

# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© participant (Ù…Ø«Ù„Ø§Ù‹ Ø§ÙˆÙ„ÛŒÙ† Ù†ÙØ± Ø¯Ø± Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…)
sample_pid = df['participant_id'].unique()[0]

# ÙÛŒÙ„ØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù† ÙØ±Ø¯ Ø®Ø§Øµ
participant_data = df[df['participant_id'] == sample_pid].sort_values('date')
participant_data = participant_data.set_index('date')

# Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
systolic = participant_data['blood_pressure_systolic'].dropna()
diastolic = participant_data['blood_pressure_diastolic'].dropna()

# PACF Ø¨Ø±Ø§ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ©
plt.figure(figsize=(10, 4))
plot_pacf(systolic, lags=3)
plt.title(f'PACF â€“ Systolic BP for Participant {sample_pid}')
plt.grid(True)
plt.show()

# PACF Ø¨Ø±Ø§ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ©
plt.figure(figsize=(10, 4))
plot_pacf(diastolic, lags=3)
plt.title(f'PACF â€“ Diastolic BP for Participant {sample_pid}')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# Ø§Ù†ØªØ®Ø§Ø¨ ÙØ±Ø¯ Ø®Ø§Øµ (Ù…Ø«Ù„Ø§Ù‹ Ø§ÙˆÙ„ÛŒÙ† Ù†ÙØ± Ø¯Ø± Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…)
sample_pid = df['participant_id'].unique()[0]

# ÙÛŒÙ„ØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ø§Ù† ÙØ±Ø¯
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# ØªÙØ§Ø¶Ù„â€ŒÚ¯ÛŒØ±ÛŒ (Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ³ØªØ§ Ú©Ø±Ø¯Ù†)
participant_data['diff_time_to_event'] = participant_data['time_to_event'].diff()

# Ø­Ø°Ù NaNÙ‡Ø§ÛŒ Ø­Ø§ØµÙ„ Ø§Ø² ØªÙØ§Ø¶Ù„â€ŒÚ¯ÛŒØ±ÛŒ
ts_diff = participant_data['diff_time_to_event'].dropna()

# Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± ACF Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† q
plt.figure(figsize=(10, 4))
plot_acf(ts_diff, lags=5)
plt.title(f"ACF â€“ time_to_event (Differenced) for Participant {sample_pid}")
plt.grid(True)
plt.show()

# Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± PACF Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† p
plt.figure(figsize=(10, 4))
plot_pacf(ts_diff, lags=3)
plt.title(f"PACF â€“ time_to_event (Differenced) for Participant {sample_pid}")
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© Ø´Ø±Ú©Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]

# ÙÛŒÙ„ØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø¢Ù† ÙØ±Ø¯
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ø§ÛŒØ¬Ø§Ø¯ lag-1 Ø¨Ø±Ø§ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ†
participant_data['lag_1_systolic'] = participant_data['blood_pressure_systolic'].shift(1)
participant_data['lag_1_diastolic'] = participant_data['blood_pressure_diastolic'].shift(1)

# Ù…ØªØºÛŒØ± ÙˆØ§Ø¨Ø³ØªÙ‡
y = participant_data['time_to_event'].astype(float)

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ØªÙˆØ¶ÛŒØ­ÛŒ Ø´Ø§Ù…Ù„ Ù…Ù‚Ø¯Ø§Ø± Ø§ØµÙ„ÛŒ Ùˆ lag-1
X = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic',
                      'lag_1_systolic', 'lag_1_diastolic']]

# Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ NaN Ø¯Ø§Ø±Ù†Ø¯ (Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ shift)
combined = pd.concat([y, X], axis=1).dropna()
y = combined['time_to_event']
X = combined[['blood_pressure_systolic', 'blood_pressure_diastolic',
              'lag_1_systolic', 'lag_1_diastolic']]

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ train Ùˆ test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]
X_train, X_test = X[:split_idx], X[split_idx:]

# Ø³Ø§Ø®Øª Ù…Ø¯Ù„ ARIMAX Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡
model = ARIMA(endog=y_train, exog=X_train, order=(1, 1, 1))
model_fit = model.fit()

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
forecast = model_fit.forecast(steps=len(y_test), exog=X_test)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum(np.square(y_test - forecast))

print("ğŸ“Š ARIMAX Model Evaluation (Main + Lagged BP):")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")


import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# Ø§Ù†ØªØ®Ø§Ø¨ participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ø§ÛŒØ¬Ø§Ø¯ lag-1 Ø¨Ø±Ø§ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ†
participant_data['lag_1_systolic'] = participant_data['blood_pressure_systolic'].shift(1)
participant_data['lag_1_diastolic'] = participant_data['blood_pressure_diastolic'].shift(1)

# Ù…ØªØºÛŒØ± Ù‡Ø¯Ù
y = participant_data['time_to_event'].astype(float)

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ØªÙˆØ¶ÛŒØ­ÛŒ: Ø§ØµÙ„ÛŒ Ùˆ lag-1
X = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic',
                      'lag_1_systolic', 'lag_1_diastolic']]

# ØªØ±Ú©ÛŒØ¨ Ùˆ Ø­Ø°Ù NaNÙ‡Ø§
combined = pd.concat([y, X], axis=1).dropna()
y = combined['time_to_event']
X = combined[['blood_pressure_systolic', 'blood_pressure_diastolic', 'lag_1_systolic', 'lag_1_diastolic']]

# Ù…Ø­Ø¯ÙˆØ¯Ù‡ pØŒ dØŒ q
p_range = range(0, 5)
d_range = [1]
q_range = range(0, 5)

best_aic = np.inf
best_order = None
results = []

# Grid Search Ø±ÙˆÛŒ (p,d,q)
for p in p_range:
    for d in d_range:
        for q in q_range:
            try:
                model = ARIMA(endog=y, exog=X, order=(p, d, q))
                model_fit = model.fit()
                aic = model_fit.aic
                results.append((p, d, q, aic))
                if aic < best_aic:
                    best_aic = aic
                    best_order = (p, d, q)
            except:
                continue

# Ù†ØªØ§ÛŒØ¬
print(f"\nâœ… Best ARIMAX Order: {best_order} with AIC = {best_aic:.2f}")
result_df = pd.DataFrame(results, columns=['p', 'd', 'q', 'AIC']).sort_values('AIC')
display(result_df)

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© Ø´Ø±Ú©Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]

# ÙÛŒÙ„ØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø¢Ù† ÙØ±Ø¯
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ø§ÛŒØ¬Ø§Ø¯ lag-1 Ø¨Ø±Ø§ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ†
participant_data['lag_1_systolic'] = participant_data['blood_pressure_systolic'].shift(1)
participant_data['lag_1_diastolic'] = participant_data['blood_pressure_diastolic'].shift(1)

# Ù…ØªØºÛŒØ± ÙˆØ§Ø¨Ø³ØªÙ‡
y = participant_data['time_to_event'].astype(float)

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ØªÙˆØ¶ÛŒØ­ÛŒ Ø´Ø§Ù…Ù„ Ù…Ù‚Ø¯Ø§Ø± Ø§ØµÙ„ÛŒ Ùˆ lag-1
X = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic',
                      'lag_1_systolic', 'lag_1_diastolic']]

# Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ NaN Ø¯Ø§Ø±Ù†Ø¯ (Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ shift)
combined = pd.concat([y, X], axis=1).dropna()
y = combined['time_to_event']
X = combined[['blood_pressure_systolic', 'blood_pressure_diastolic',
              'lag_1_systolic', 'lag_1_diastolic']]

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ train Ùˆ test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]
X_train, X_test = X[:split_idx], X[split_idx:]

# Ø³Ø§Ø®Øª Ù…Ø¯Ù„ ARIMAX Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡
model = ARIMA(endog=y_train, exog=X_train, order=(3, 1, 0))
model_fit = model.fit()

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
forecast = model_fit.forecast(steps=len(y_test), exog=X_test)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum(np.square(y_test - forecast))

print("ğŸ“Š ARIMAX Model Evaluation (Main + Lagged BP):")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ù…ØªØºÛŒØ± Ù‡Ø¯Ù
y = participant_data['time_to_event'].astype(float)

# ÙÙ‚Ø· Ø®ÙˆØ¯ ÙØ´Ø§Ø± Ø®ÙˆÙ†â€ŒÙ‡Ø§ (Ø¨Ø¯ÙˆÙ† lag)
X = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic']]

# Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± NaN (Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
combined = pd.concat([y, X], axis=1).dropna()
y = combined['time_to_event']
X = combined[['blood_pressure_systolic', 'blood_pressure_diastolic']]

# ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]
X_train, X_test = X[:split_idx], X[split_idx:]

# Ø³Ø§Ø®Øª Ù…Ø¯Ù„ ARIMAX (Ø¨Ø¯ÙˆÙ† lagÙ‡Ø§)
model = ARIMA(endog=y_train, exog=X_train, order=(1, 1, 1))
model_fit = model.fit()

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
forecast = model_fit.forecast(steps=len(y_test), exog=X_test)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum(np.square(y_test - forecast))

print("ğŸ“Š ARIMAX Ø¨Ø¯ÙˆÙ† lag:")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# Ø§Ù†ØªØ®Ø§Ø¨ participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ù…ØªØºÛŒØ± Ù‡Ø¯Ù
y = participant_data['time_to_event'].astype(float)

# ÙÙ‚Ø· Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø¨Ø¯ÙˆÙ† lag
X = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic']]

# Ø­Ø°Ù NaN
combined = pd.concat([y, X], axis=1).dropna()
y = combined['time_to_event']
X = combined[['blood_pressure_systolic', 'blood_pressure_diastolic']]

# ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]
X_train, X_test = X[:split_idx], X[split_idx:]

# Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¨Ø±Ø§ÛŒ Grid Search
p_range = range(0, 4)
d_range = [1]  # Ú†ÙˆÙ† Ù…ÛŒâ€ŒØ¯ÙˆÙ†ÛŒÙ… Ø³Ø±ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² ÛŒÚ© ØªÙØ§Ø¶Ù„ Ø§ÛŒØ³ØªØ§ Ø´Ø¯Ù‡
q_range = range(0, 4)

best_aic = np.inf
best_order = None
results = []

# Grid Search
for p in p_range:
    for d in d_range:
        for q in q_range:
            try:
                model = ARIMA(endog=y_train, exog=X_train, order=(p, d, q))
                model_fit = model.fit()
                aic = model_fit.aic
                results.append((p, d, q, aic))
                if aic < best_aic:
                    best_aic = aic
                    best_order = (p, d, q)
            except:
                continue

# Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
print(f"âœ… Best ARIMAX order (no lag): {best_order} with AIC = {best_aic:.2f}")

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯Ù„
best_model = ARIMA(endog=y_train, exog=X_train, order=best_order)
best_model_fit = best_model.fit()

forecast = best_model_fit.forecast(steps=len(y_test), exog=X_test)

mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum(np.square(y_test - forecast))

print("\nğŸ“Š Evaluation of Best ARIMAX Model (no lag):")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ù…ØªØºÛŒØ± Ù‡Ø¯Ù ÙÙ‚Ø· time_to_event
y = participant_data['time_to_event'].dropna().astype(float)

# ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]

# Ø³Ø§Ø®Øª Ù…Ø¯Ù„ ARIMA Ø¨Ø§ ÙˆÙ‚ÙÙ‡ (1,1,1)
model = ARIMA(y_train, order=(1, 1, 1))
model_fit = model.fit()

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
forecast = model_fit.forecast(steps=len(y_test))

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum(np.square(y_test - forecast))

print("ğŸ“Š ARIMA(1,1,1) ÙÙ‚Ø· Ø¨Ø§ time_to_event:")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ù…ØªØºÛŒØ± Ù‡Ø¯Ù ÙÙ‚Ø· time_to_event
y = participant_data['time_to_event'].dropna().astype(float)

# ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]

# Ø³Ø§Ø®Øª Ù…Ø¯Ù„ ARIMA Ø¨Ø§ ÙˆÙ‚ÙÙ‡ (1,1,1)
model = ARIMA(y_train, order=(3, 1, 0))
model_fit = model.fit()

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
forecast = model_fit.forecast(steps=len(y_test))

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum(np.square(y_test - forecast))

print("ğŸ“Š ARIMA(3,1,0) ÙÙ‚Ø· Ø¨Ø§ time_to_event:")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")

import pandas as pd

# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ùˆ Ø³ØªÙˆÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ùˆ Ø­Ø°Ù NaN (Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ VIF)
X = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic']].dropna()

# Ù…Ø­Ø§Ø³Ø¨Ù‡ VIF
vif_data = pd.DataFrame()
vif_data["feature"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
print("ğŸ“Š Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…â€ŒØ®Ø·ÛŒ Ø¨ÛŒÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ø³ÛŒØ³ØªÙˆÙ„ÛŒÚ© Ùˆ Ø¯ÛŒØ§Ø³ØªÙˆÙ„ÛŒÚ© Ø¨Ø±Ø§ÛŒ participant:", sample_pid)
print(vif_data)


import pandas as pd

# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# Ø§Ù†ØªØ®Ø§Ø¨ ÙÙ‚Ø· Ø¯Ùˆ Ø³ØªÙˆÙ† ÙØ´Ø§Ø± Ø®ÙˆÙ† Ùˆ Ø­Ø°Ù NaN
X_bp = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic']].dropna()

# Ù…Ù‚ÛŒØ§Ø³â€ŒÚ¯Ø°Ø§Ø±ÛŒ (Standardization)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_bp)

# Ø§Ø¹Ù…Ø§Ù„ PCA (ÙÙ‚Ø· Ù…Ø¤Ù„ÙÙ‡ Ø§ÙˆÙ„)
pca = PCA(n_components=1)
X_pca = pca.fit_transform(X_scaled)

# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame Ø¨Ø§ Ø­ÙØ¸ ØªØ§Ø±ÛŒØ®
X_pca_df = pd.DataFrame(X_pca, index=X_bp.index, columns=['pc1'])

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† pc1 Ø¨Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… participant
participant_data.loc[X_pca_df.index, 'pc1'] = X_pca_df['pc1']

# Ù†Ù…Ø§ÛŒØ´ Ú†Ù†Ø¯ Ø³Ø·Ø± Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ
print(participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic', 'pc1']].head())


print(f"Explained variance ratio by PC1: {pca.explained_variance_ratio_[0]:.4f}")


# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø§ØµÙ„ÛŒ (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
participant_data['pc1'] = X_pca_df


import matplotlib.pyplot as plt

# Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ
ts = participant_data['pc1'].dropna()

# Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ† ADF
adf_result = adfuller(ts)
print("ADF Statistic:", adf_result[0])
print("p-value:", adf_result[1])
for key, value in adf_result[4].items():
    print(f"Critical Value ({key}): {value:.4f}")

# ØªÙØ³ÛŒØ± Ù†ØªÛŒØ¬Ù‡
if adf_result[1] < 0.05:
    print("\nâœ… Series is stationary (reject H0)")
else:
    print("\nâŒ Series is non-stationary (fail to reject H0)")

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# 1. Ø§Ù†ØªØ®Ø§Ø¨ participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# 2. Ø§Ø¬Ø±Ø§ÛŒ PCA Ø±ÙˆÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ†â€ŒÙ‡Ø§
X_bp = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic']].dropna()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_bp)

pca = PCA(n_components=1)
X_pca = pca.fit_transform(X_scaled)

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† pc1 Ø¨Ù‡ participant_data
X_pca_df = pd.DataFrame(X_pca, index=X_bp.index, columns=['pc1'])
participant_data.loc[X_pca_df.index, 'pc1'] = X_pca_df['pc1']

# 3. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† lag-1 Ø§Ø² pc1
participant_data['pc1_lag1'] = participant_data['pc1'].shift(1)

# 4. Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
data = participant_data[['time_to_event', 'pc1_lag1']].dropna()
y = data['time_to_event']
X = data[['pc1_lag1']]

# 5. ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]
X_train, X_test = X[:split_idx], X[split_idx:]

# 6. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ARIMAX(1,1,1)
model = ARIMA(endog=y_train, exog=X_train, order=(1, 1, 1))
model_fit = model.fit()

# 7. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
forecast = model_fit.forecast(steps=len(y_test), exog=X_test)

# 8. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum((y_test - forecast) ** 2)

print(f"\nğŸ“Š ARIMAX(1,1,1) Ø¨Ø§ pc1_lag1 Ø¨Ø±Ø§ÛŒ participant {sample_pid}:")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# 1. Ø§Ù†ØªØ®Ø§Ø¨ participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# 2. Ø§Ø¬Ø±Ø§ÛŒ PCA Ø±ÙˆÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ†â€ŒÙ‡Ø§
X_bp = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic']].dropna()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_bp)

pca = PCA(n_components=1)
X_pca = pca.fit_transform(X_scaled)

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† pc1 Ø¨Ù‡ participant_data
X_pca_df = pd.DataFrame(X_pca, index=X_bp.index, columns=['pc1'])
participant_data.loc[X_pca_df.index, 'pc1'] = X_pca_df['pc1']

# 3. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† lag-1 Ø§Ø² pc1
participant_data['pc1_lag1'] = participant_data['pc1'].shift(1)

# 4. Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
data = participant_data[['time_to_event', 'pc1_lag1']].dropna()
y = data['time_to_event']
X = data[['pc1_lag1']]

# 5. ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]
X_train, X_test = X[:split_idx], X[split_idx:]

# 6. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ARIMAX(1,1,1)
model = ARIMA(endog=y_train, exog=X_train, order=(3, 1, 0))
model_fit = model.fit()

# 7. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
forecast = model_fit.forecast(steps=len(y_test), exog=X_test)

# 8. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum((y_test - forecast) ** 2)

print(f"\nğŸ“Š ARIMAX(3,1,0) Ø¨Ø§ pc1_lag1 Ø¨Ø±Ø§ÛŒ participant {sample_pid}:")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# 1. Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# 2. Ø§Ø¬Ø±Ø§ÛŒ PCA Ø±ÙˆÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ†â€ŒÙ‡Ø§
X_bp = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic']].dropna()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_bp)

pca = PCA(n_components=1)
X_pca = pca.fit_transform(X_scaled)

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† pc1 Ø¨Ù‡ participant_data
X_pca_df = pd.DataFrame(X_pca, index=X_bp.index, columns=['pc1'])
participant_data.loc[X_pca_df.index, 'pc1'] = X_pca_df['pc1']

# 3. Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø¯ÙˆÙ† lag
data = participant_data[['time_to_event', 'pc1']].dropna()
y = data['time_to_event']
X = data[['pc1']]

# 4. ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]
X_train, X_test = X[:split_idx], X[split_idx:]

# 5. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ARIMAX(1,1,1)
model = ARIMA(endog=y_train, exog=X_train, order=(1, 1, 1))
model_fit = model.fit()

# 6. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
forecast = model_fit.forecast(steps=len(y_test), exog=X_test)

# 7. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum((y_test - forecast) ** 2)

print(f"\nğŸ“Š ARIMAX(1,1,1) Ø¨Ø§ pc1 Ø¨Ø¯ÙˆÙ† lag Ø¨Ø±Ø§ÛŒ participant {sample_pid}:")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")


import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# 1. Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# 2. Ø§Ø¬Ø±Ø§ÛŒ PCA Ø±ÙˆÛŒ ÙØ´Ø§Ø± Ø®ÙˆÙ†â€ŒÙ‡Ø§
X_bp = participant_data[['blood_pressure_systolic', 'blood_pressure_diastolic']].dropna()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_bp)

pca = PCA(n_components=1)
X_pca = pca.fit_transform(X_scaled)

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† pc1 Ø¨Ù‡ participant_data
X_pca_df = pd.DataFrame(X_pca, index=X_bp.index, columns=['pc1'])
participant_data.loc[X_pca_df.index, 'pc1'] = X_pca_df['pc1']

# 3. Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø¯ÙˆÙ† lag
data = participant_data[['time_to_event', 'pc1']].dropna()
y = data['time_to_event']
X = data[['pc1']]

# 4. ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]
X_train, X_test = X[:split_idx], X[split_idx:]

# 5. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ARIMAX(1,1,1)
model = ARIMA(endog=y_train, exog=X_train, order=(3, 1, 0))
model_fit = model.fit()

# 6. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
forecast = model_fit.forecast(steps=len(y_test), exog=X_test)

# 7. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
mae = mean_absolute_error(y_test, forecast)
mse = mean_squared_error(y_test, forecast)
rss = np.sum((y_test - forecast) ** 2)

print(f"\nğŸ“Š ARIMAX(3,1,0) Ø¨Ø§ pc1 Ø¨Ø¯ÙˆÙ† lag Ø¨Ø±Ø§ÛŒ participant {sample_pid}:")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.5f}")
print(f"RSS: {rss:.5f}")




import matplotlib.pyplot as plt
import plotly.graph_objects as go

import numpy as np
import pandas as pd
import random

# ğŸ”¹ 1. ØªÙ†Ø¸ÛŒÙ… seed Ø¨Ø±Ø§ÛŒ reproducibility
seed = 42
tf.random.set_seed(seed)
np.random.seed(seed)
random.seed(seed)

# ğŸ”¹ 2. Ø§Ù†ØªØ®Ø§Ø¨ ÙÙ‚Ø· ÛŒÚ© participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# ğŸ”¹ 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ time_to_event
ts = participant_data['time_to_event'].dropna().sort_index()

# ğŸ”¹ 4. Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ MinMaxScaler Ø¯Ø± Ø¨Ø§Ø²Ù‡ [0,1]
scaler = MinMaxScaler()
ts_scaled = scaler.fit_transform(ts.values.reshape(-1, 1))

# ğŸ”¹ 5. Ø³Ø§Ø®Øª Ø¯Ù†Ø¨Ø§Ù„Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ/Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø±Ø§ÛŒ RNN
def create_sequences(data, seq_len=2):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len])
    return np.array(X), np.array(y)

seq_length = 2
X_all, y_all = create_sequences(ts_scaled, seq_length)
X_all = X_all.reshape((X_all.shape[0], X_all.shape[1], 1))  # (samples, timesteps, features)

# ğŸ”¹ 6. ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train Ùˆ test
split_idx = int(len(X_all) * 0.8)
X_train, X_test = X_all[:split_idx], X_all[split_idx:]
y_train, y_test = y_all[:split_idx], y_all[split_idx:]

# ğŸ”¹ 7. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ RNN
model = Sequential([
    SimpleRNN(50, activation='relu', input_shape=(seq_length, 1)),
    Dense(1)
])
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=100, verbose=0)

# ğŸ”¹ 8. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù…Ù‚ÛŒØ§Ø³ Ø§ØµÙ„ÛŒ
rnn_pred_scaled = model.predict(X_test)
y_test_inv = scaler.inverse_transform(y_test)
rnn_pred_inv = scaler.inverse_transform(rnn_pred_scaled)

# ğŸ”¹ 9. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„
rnn_mae = mean_absolute_error(y_test_inv, rnn_pred_inv)
rnn_mse = mean_squared_error(y_test_inv, rnn_pred_inv)
rnn_rss = np.sum((y_test_inv - rnn_pred_inv) ** 2)

print(f"ğŸ“Š Ù†ØªØ§ÛŒØ¬ RNN Ø¨Ø±Ø§ÛŒ participant {sample_pid}:")
print(f"MAE: {rnn_mae:.2f}")
print(f"MSE: {rnn_mse:.2f}")
print(f"RSS: {rnn_rss:.2f}")

import numpy as np
import pandas as pd

# 1. Ø§Ù†ØªØ®Ø§Ø¨ Ù‡Ù…Ø§Ù† participant Ø®Ø§Øµ
sample_pid = df['participant_id'].unique()[0]
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')

# 2. ØªØ¹Ø±ÛŒÙ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ time_to_event (Ø¨Ø¯ÙˆÙ† NaN)
y = participant_data['time_to_event'].dropna().astype(float)

# 3. ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ train/test
split_idx = int(len(y) * 0.8)
y_train, y_test = y[:split_idx], y[split_idx:]

# 4. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ARIMA(3,1,0)
arima_model = ARIMA(y_train, order=(3, 1, 0))
arima_result = arima_model.fit()

# 5. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
arima_forecast = arima_result.forecast(steps=len(y_test))

# 6. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§Ù‡Ø§ Ùˆ log-likelihood
arima_mae = mean_absolute_error(y_test, arima_forecast)
arima_mse = mean_squared_error(y_test, arima_forecast)
arima_rss = np.sum((y_test - arima_forecast) ** 2)
arima_llf = arima_result.llf  # log-likelihood of ARIMA

# 7. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù…Ø¯Ù„ RNN
# ÙØ±Ø¶: Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ RNN Ù‚Ø¨Ù„ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ø³ØªÙ†:
# rnn_mae, rnn_mse, rnn_rss, y_test_inv

# 8. Ù…Ø­Ø§Ø³Ø¨Ù‡ log-likelihood ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ RNN Ùˆ Ø¢Ø²Ù…ÙˆÙ† Ù†Ø³Ø¨Øª Ø¯Ø±Ø³Øªâ€ŒÙ†Ù…Ø§ÛŒÛŒ
log_likelihood_rnn = -0.5 * len(y_test_inv) * np.log(rnn_mse)
log_likelihood_ratio = 2 * (arima_llf - log_likelihood_rnn)

# 9. Ú†Ø§Ù¾ Ù†ØªØ§ÛŒØ¬
print("===== ARIMA Model (3,1,0) =====")
print(f"MAE: {arima_mae:.2f}, MSE: {arima_mse:.2f}, RSS: {arima_rss:.2f}, Log-Likelihood: {arima_llf:.2f}")

print("\n===== RNN Model =====")
print(f"MAE: {rnn_mae:.2f}, MSE: {rnn_mse:.2f}, RSS: {rnn_rss:.2f}")

print("\n===== Log Likelihood Ratio (ARIMA vs RNN) =====")
print(f"LLR: {log_likelihood_ratio:.2f}")


import matplotlib.pyplot as plt

# Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡
# y_test: Ù…Ø´Ø§Ù‡Ø¯Ø§Øª ÙˆØ§Ù‚Ø¹ÛŒ time_to_event Ø¨Ø±Ø§ÛŒ ØªØ³Øª
# arima_forecast: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ARIMA Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª
# rnn_pred_inv: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ RNN (Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³ Ø§ØµÙ„ÛŒ)
# ts: Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø§ØµÙ„ÛŒ Ú©Ø§Ù…Ù„ time_to_event

# Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª (Ù‡Ù…Ø§Ù† Ø¨Ø§Ø²Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ø±Ø¯ÛŒÙ…)
plot_index = y_test.index

plt.figure(figsize=(12, 6))

# Ø®Ø· Ù…Ø´Ø§Ù‡Ø¯Ø§Øª ÙˆØ§Ù‚Ø¹ÛŒ
plt.plot(plot_index, y_test.values, label="Actual", marker='o')

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ARIMA
plt.plot(plot_index, arima_forecast.values, label="ARIMA Forecast", marker='x')

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ RNN (Ø¨Ø§ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¬Ø¯ÛŒØ¯ Ø³Ø§Ø®ØªÙ‡â€ŒØ´Ø¯Ù‡ Ø§Ø² Ù‡Ù…Ø§Ù† Ø·ÙˆÙ„)
rnn_plot_index = plot_index[-len(rnn_pred_inv):]  # Ø¯Ø± ØµÙˆØ±Øª Ø§Ø®ØªÙ„Ø§Ù Ø·ÙˆÙ„
plt.plot(rnn_plot_index, rnn_pred_inv.flatten(), label="RNN Forecast", marker='^')

plt.title(f"Forecast Comparison â€“ ARIMA vs RNN (Participant {sample_pid})")
plt.xlabel("Date")
plt.ylabel("Time to Event")
plt.gca().invert_yaxis()  # Ú†ÙˆÙ† Ú©Ø§Ù‡Ø´ Ù…Ù‚Ø¯Ø§Ø± time_to_event ÛŒØ¹Ù†ÛŒ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ± Ø´Ø¯Ù† Ø¨Ù‡ event
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
seq_length = 5  # Ø·ÙˆÙ„ ØªÙˆØ§Ù„ÛŒâ€ŒÙ‡Ø§ØŒ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù‚Ø§Ø¨Ù„ ØªØºÛŒÛŒØ±
sample_pid = df['participant_id'].unique()[0]

# ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡ Ø´Ø±Ú©Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡
participant_data = df[df['participant_id'] == sample_pid].sort_values('date').set_index('date')
ts = participant_data['time_to_event'].astype(float)

# Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
scaler = MinMaxScaler()
ts_scaled = scaler.fit_transform(ts.values.reshape(-1, 1))

# ØªØ§Ø¨Ø¹ Ø³Ø§Ø®Øª ØªÙˆØ§Ù„ÛŒ X Ùˆ y
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

# Ø³Ø§Ø®Øª ØªÙˆØ§Ù„ÛŒâ€ŒÙ‡Ø§
X_train, y_train = create_sequences(ts_scaled, seq_length)
X_train = X_train.reshape((X_train.shape[0], seq_length, 1))

# Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ
if len(X_train) == 0:
    print("â— Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ LSTM ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. seq_length Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯ ÛŒØ§ Ø´Ø±Ú©Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡â€ŒÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
else:
    # ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„ LSTM
    lstm_model = Sequential([
        LSTM(50, activation='tanh', input_shape=(seq_length, 1)),
        Dense(1)
    ])
    lstm_model.compile(optimizer='adam', loss='mse')
    lstm_model.fit(X_train, y_train, epochs=50, verbose=1)

    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    lstm_pred_scaled = lstm_model.predict(X_train)
    lstm_pred = scaler.inverse_transform(lstm_pred_scaled)
    actual_y = scaler.inverse_transform(y_train)

    # Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±
    plt.figure(figsize=(12, 6))
    plt.plot(actual_y, label='Actual', marker='o')
    plt.plot(lstm_pred, label='LSTM Prediction', marker='^')
    plt.title(f'LSTM Forecast vs Actual â€“ Participant {sample_pid}')
    plt.xlabel('Time step')
    plt.ylabel('Time to Event (days)')
    plt.gca().invert_yaxis()  # Ú†ÙˆÙ† Ø´Ù…Ø§Ø±Ø´ Ù…Ø¹Ú©ÙˆØ³Ù‡
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Predict on test set
lstm_pred_scaled = lstm_model.predict(X_test)

# Evaluate
mae = mean_absolute_error(y_test, lstm_pred_scaled)
mse = mean_squared_error(y_test, lstm_pred_scaled)
rss = np.sum((y_test - lstm_pred_scaled) ** 2)
print("===== LSTM Model (Global) =====")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.4f}")
print(f"RSS: {rss:.4f}")

#Prepare global LSTM sequences
seq_length = 5
grouped = df.groupby('participant_id')
all_sequences = []

for pid, group in grouped:
    if len(group) >= seq_length + 1:
        series = group.sort_values('date')['time_to_event'].values
        scaler = MinMaxScaler()
        scaled_series = scaler.fit_transform(series.reshape(-1, 1))
        for i in range(len(scaled_series) - seq_length):
            X_seq = scaled_series[i:i+seq_length]
            y_seq = scaled_series[i+seq_length]
            all_sequences.append((X_seq, y_seq))

X_all = np.array([seq[0] for seq in all_sequences])
y_all = np.array([seq[1] for seq in all_sequences])
X_all = X_all.reshape((X_all.shape[0], seq_length, 1))

#Training our LSTM model
model = Sequential([
    LSTM(50, activation='tanh', input_shape=(seq_length, 1)),
    Dense(1)
])
model.compile(optimizer='adam', loss='mse')
model.fit(X_all, y_all, epochs=50, verbose=0)
#Prediction
def predict_non_hypertensive_date(df, participant_id, model, seq_length=5):
    df_part = df[df['participant_id'] == participant_id].sort_values('date')
    ts = df_part.set_index('date')['time_to_event'].astype(float)

    if len(ts) <= seq_length + 1:
        return None

    scaler = MinMaxScaler()
    ts_scaled = scaler.fit_transform(ts.values.reshape(-1, 1))

    X_p = np.array([ts_scaled[i:i+seq_length] for i in range(len(ts_scaled) - seq_length)])
    X_p = X_p.reshape((X_p.shape[0], seq_length, 1))

    preds_scaled = model.predict(X_p)
    preds = scaler.inverse_transform(preds_scaled)

    dates = ts.index[seq_length:]
    for date, val in zip(dates, preds.flatten()):
        if val <= 0.5:  # Threshold for predicting recovery
            return date

    return dates[-1]

#to all participant applying
results = []
for pid in df['participant_id'].unique():
    pred_date = predict_non_hypertensive_date(df, pid, model)
    if pred_date is not None:
        results.append({
            'participant_id': pid,
            'predicted_non_hypertensive_date': pred_date
        })

# Create and save our results
forecast_df = pd.DataFrame(results)
forecast_df = forecast_df.sort_values("predicted_non_hypertensive_date")

# View the result
print(forecast_df.head())

def plot_participant_forecast(df, participant_id, model, seq_length=5):
    df_part = df[df['participant_id'] == participant_id].sort_values('date')
    ts = df_part.set_index('date')['time_to_event'].astype(float)

    if len(ts) <= seq_length + 1:
        print(f"Participant {participant_id} has too few records.")
        return

    scaler = MinMaxScaler()
    ts_scaled = scaler.fit_transform(ts.values.reshape(-1, 1))

    X_p = np.array([ts_scaled[i:i+seq_length] for i in range(len(ts_scaled) - seq_length)])
    X_p = X_p.reshape((X_p.shape[0], seq_length, 1))
    preds_scaled = model.predict(X_p)
    preds = scaler.inverse_transform(preds_scaled)

    dates = ts.index[seq_length:]
    actual = ts[seq_length:]

    plt.figure(figsize=(10, 5))
    plt.plot(ts.index, ts.values, label="Actual Time to Event", marker='o')
    plt.plot(dates, preds.flatten(), label="LSTM Prediction", linestyle='--', marker='x')
    plt.title(f"Participant {participant_id} â€“ LSTM Forecast")
    plt.xlabel("Date")
    plt.ylabel("Time to Event")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Example usage:
for pid in df['participant_id'].unique()[:30]:  # first 5 participants if we want to see for more participants we can adjust it
    plot_participant_forecast(df, pid, model)

def plot_forecast_for_participant(df, participant_id, model, seq_length=5):
    df_part = df[df['participant_id'] == participant_id].sort_values('date')
    ts = df_part.set_index('date')['time_to_event'].astype(float)

    if len(ts) <= seq_length + 1:
        return

    scaler = MinMaxScaler()
    ts_scaled = scaler.fit_transform(ts.values.reshape(-1, 1))
    X = np.array([ts_scaled[i:i+seq_length] for i in range(len(ts_scaled) - seq_length)])
    X = X.reshape((X.shape[0], seq_length, 1))

    pred_scaled = model.predict(X)
    pred = scaler.inverse_transform(pred_scaled)

    dates = ts.index[seq_length:]

    plt.plot(ts.index, ts.values, label="Actual", marker='o')
    plt.plot(dates, pred.flatten(), label="LSTM Forecast", linestyle='--', marker='x')
    plt.title(f"Participant {participant_id}")
    plt.xlabel("Date")
    plt.ylabel("Time to Event")
    plt.legend()
    plt.grid(True)

# Creating dashboard for 6 participants
sample_participants = df['participant_id'].value_counts().loc[lambda x: x >= 10].index[:6]

fig, axes = plt.subplots(3, 2, figsize=(15, 12))
axes = axes.flatten()

for idx, pid in enumerate(sample_participants):
    plt.sca(axes[idx])
    plot_forecast_for_participant(df, pid, model)

plt.suptitle("LSTM Forecast Dashboard â€“ Time to Non-Hypertensive State", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()
